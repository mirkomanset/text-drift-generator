{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "while not os.getcwd().endswith(\"text-drift-generator\"):\n",
    "    os.chdir(\"..\")\n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from scripts.enums import WordErrorType\n",
    "from scripts.preprocess import preprocess_text\n",
    "from scripts.drift_generator import simulate_drift\n",
    "from scripts.utils import generate_drifted_text, plot_cosine_similarity\n",
    "from scripts.constants import EXAMPLE_STRING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test simulate error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating typographical errors:\n",
      "Stage 0.1: Artificial intellignce is revolutionizing the way we live and work. It is transforming industries yb automating tasks, impzproving efficiency, and enhancing decision-making. As AI technology evolves, it opens up new possibilities for businesses and individuals avlike. However, challenges remain in ensuring ethical use, data privacy, and fairness. As we move forward, it's crucial to balance innovation with responsibility to maximize the benefits while minimizing ridks.\n",
      "Stage 0.5: Ahrtifuial intelligence is gevuolutonizing the ay we liv eagnd work. It ist ransforming industqries by automating taaks, improving efficeinc,y ad enhancijg decjsion-makngi. As Au technology evopve,si t opens up new posziblites for vbusinesses and iyndividualss azlgike. However, challengew remain iln ensuring ethical uet, data privacy, gand fairnecss. A we move forward, it's crucial to balance innovaion wigh respjonsibilityv to mazomize the benehfits wile minimizing risks.\n",
      "Stage 0.9: Ahrtifuial intelljgenxe iz urevoutionizgingthe way w elgive and work. tIis transfyotming nidusriepzsb y akyomating takss,i mpoving effjciencg,and enhanicng decsiion-makigng. w sIA ehcnology evolcsc, tit opes utp new pkyfssiibltiizsg for busiezsses adn indivdulals aflioe. Howevrt, challemges rgemain in nesuingethical ues, data prvacy, and fairness. Ahs w kve forwardj, it's cruvciwl to galance innovahtion wthresponsdibility to maximjazeu te benefits while minimizing risks.\n",
      "\n",
      "Simulating phonetic errors:\n",
      "Stage 0.1: Artificial intelligence is revolutionizing the way we live and work. It 1 transforming industries by automating tasks, improving efficiency, and enhancing decision-making. As AI technology evolves, it opens up new possibilities for businesses and individuals alike. However, challenges remain in ensuring ethical use, data privacy, and fairness. a we move forward, it's crucial to balance innovation with responsibility too maximize the benefits while minimizing risks.\n",
      "Stage 0.5: eye intelligence is u the e we live and work. It is transforming industries by oa tasks, improving efficiency, and e decision-making. As AI technology 0 it opens up new possibilities for yoo and individuals alike. However, challenges remain in ensuring ethical use, data privacy, and fairness. As we ea forward, it's crucial to balance innovation with responsibility to eh the benefits while minimizing risks.\n",
      "Stage 0.9: eye i is o da way we live and work. ai is oh industries by automating tasks, improving 3 and enhancing ea As AI oa evolves, it opens up e oh for you and individuals alike. o e eh in ensuring ea use, a privacy, and a As we 3 4r it's @ to ah oa with eh to maximize the benefits e minimizing risks.\n",
      "\n",
      "Simulating mix errors:\n",
      "Stage 0.1: Artificial intelligence is revolutionizing the way we live and work. It is transforming industries by automating tasks, imprpoving efficiency, and enhancing decision-making. As AI technology evolves, it opens up new possibilities for businesses and individuals alike. However, challenges rmain in ensuring ethical use, data privacy, and fairness. As we move forward it's crucial to balgance innovation with responsibility to eye the benefits while minimizing risks.\n",
      "Stage 0.5: Artificial intellignce is revolutionizing the way we live and work. It 1 transforming industries yb automating tasks, impzproving efficiency, and enhancing decision-making. As AI technology evolves, it opens up new possibilities for businesses and individuals avlike. However, challenges remain in ensuring ethical use, data privacy, and fairness. a we move forward, it's crucial to balance innovation with responsibility too maximize the benefits while minimizing ridks.\n",
      "Stage 0.9: eye intelligence is u the e we live and work. It is transforming industries by autoqmating tasks, improving efficiency, and enhacnig decision-making. As AI technology evolves, it opens up new possibilities for businesses and individuals valike. However, challenges remain in ensuring ethical use, data privacy, and faifrness. As we move forward, it's @ to balance innovation with responsibility to maximize the benefits while minimizinhj risks.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "text = EXAMPLE_STRING\n",
    "error_types = [\n",
    "    WordErrorType.TYPOGRAPHICAL,\n",
    "    WordErrorType.PHONETIC,\n",
    "    WordErrorType.MIX,\n",
    "]\n",
    "\n",
    "levels = [0.1, 0.5, 0.9]\n",
    "\n",
    "for error_type in error_types:\n",
    "    print(f\"\\nSimulating {error_type} errors:\")\n",
    "    for level in levels:\n",
    "        drifted_text = simulate_drift(text, error_type, level)\n",
    "        print(f\"Stage {level}: {drifted_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['comp.graphics', 'rec.autos', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.med', 'talk.politics.misc']\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    \"comp.graphics\",\n",
    "    \"rec.autos\",\n",
    "    \"rec.sport.baseball\",\n",
    "    \"rec.sport.hockey\",\n",
    "    \"sci.med\",\n",
    "    \"talk.politics.misc\",\n",
    "]\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_20newsgroups(\n",
    "    subset=\"all\",\n",
    "    categories=categories,\n",
    "    shuffle=False,\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [0.1, 0.5, 0.9]\n",
    "typo_full_dfs = []\n",
    "pho_full_dfs = []\n",
    "mix_full_dfs = []\n",
    "error_types = [WordErrorType.TYPOGRAPHICAL, WordErrorType.PHONETIC, WordErrorType.MIX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply drift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating typographical errors at level 0.1:\n",
      "Done in 6.776171684265137 s\n",
      "\n",
      "Simulating phonetic errors at level 0.1:\n",
      "Done in 7.4782938957214355 s\n",
      "\n",
      "Simulating mix errors at level 0.1:\n",
      "Done in 7.919825792312622 s\n",
      "\n",
      "Simulating typographical errors at level 0.5:\n",
      "Done in 7.7730793952941895 s\n",
      "\n",
      "Simulating phonetic errors at level 0.5:\n",
      "Done in 8.411454916000366 s\n",
      "\n",
      "Simulating mix errors at level 0.5:\n",
      "Done in 8.244817018508911 s\n",
      "\n",
      "Simulating typographical errors at level 0.9:\n",
      "Done in 8.169755220413208 s\n",
      "\n",
      "Simulating phonetic errors at level 0.9:\n",
      "Done in 9.791260242462158 s\n",
      "\n",
      "Simulating mix errors at level 0.9:\n",
      "Done in 10.498154163360596 s\n"
     ]
    }
   ],
   "source": [
    "for level in levels:\n",
    "    drifted_df = generate_drifted_text(df=df, error_type=WordErrorType.TYPOGRAPHICAL, level=level, print_info=True)\n",
    "    typo_full_dfs.append(drifted_df)\n",
    "    drifted_df = generate_drifted_text(df=df, error_type=WordErrorType.PHONETIC, level=level, print_info=True)\n",
    "    pho_full_dfs.append(drifted_df)\n",
    "    drifted_df = generate_drifted_text(df=df, error_type=WordErrorType.MIX, level=level, print_info=True)\n",
    "    mix_full_dfs.append(drifted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing typographical original 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:46<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing typographical drifted 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:47<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing phonetic original 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:42<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing phonetic drifted 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:44<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing mix original 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:44<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing mix drifted 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:46<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing typographical original 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:45<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing typographical drifted 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [02:04<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing phonetic original 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:49<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing phonetic drifted 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:46<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing mix original 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:50<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing mix drifted 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:54<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing typographical original 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:56<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing typographical drifted 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [02:16<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing phonetic original 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:50<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing phonetic drifted 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:44<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing mix original 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:48<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorizing mix drifted 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 173/173 [01:53<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Prepare your data in batches for more efficient encoding\n",
    "batch_size = 32  # You can adjust this based on your system's capacity\n",
    "\n",
    "X_drifted_list = []\n",
    "X_list = []\n",
    "\n",
    "for i in range(len(levels)):\n",
    "    print(f\"start vectorizing typographical original {levels[i]}\")\n",
    "    # Encode in batches\n",
    "    original_data = typo_full_dfs[i].original_preprocessed_data\n",
    "    X = model.encode(original_data, batch_size=batch_size, show_progress_bar=True, device='cpu')  # Ensure CPU usage\n",
    "    X_list.append(X)\n",
    "    np.savetxt(f'data/drifted_data/typographical/original_{levels[i]}.csv', X, delimiter=',')\n",
    "\n",
    "    print(f\"start vectorizing typographical drifted {levels[i]}\")\n",
    "    # Encode drifted data in batches\n",
    "    drifted_data = typo_full_dfs[i].drifted_preprocessed_data\n",
    "    X_drifted = model.encode(drifted_data, batch_size=batch_size, show_progress_bar=True, device='cpu')  # Ensure CPU usage\n",
    "    X_drifted_list.append(X_drifted)\n",
    "    np.savetxt(f'data/drifted_data/typographical/drifted_{levels[i]}.csv', X_drifted, delimiter=',')\n",
    "\n",
    "    print(f\"start vectorizing phonetic original {levels[i]}\")\n",
    "    # Encode in batches\n",
    "    original_data = pho_full_dfs[i].original_preprocessed_data\n",
    "    X = model.encode(original_data, batch_size=batch_size, show_progress_bar=True, device='cpu')  # Ensure CPU usage\n",
    "    X_list.append(X)\n",
    "    np.savetxt(f'data/drifted_data/phonetic/original_{levels[i]}.csv', X, delimiter=',')\n",
    "\n",
    "    print(f\"start vectorizing phonetic drifted {levels[i]}\")\n",
    "    # Encode drifted data in batches\n",
    "    drifted_data = pho_full_dfs[i].drifted_preprocessed_data\n",
    "    X_drifted = model.encode(drifted_data, batch_size=batch_size, show_progress_bar=True, device='cpu')  # Ensure CPU usage\n",
    "    X_drifted_list.append(X_drifted)\n",
    "    np.savetxt(f'data/drifted_data/phonetic/drifted_{levels[i]}.csv', X_drifted, delimiter=',')\n",
    "\n",
    "    print(f\"start vectorizing mix original {levels[i]}\")\n",
    "    # Encode in batches\n",
    "    original_data = mix_full_dfs[i].original_preprocessed_data\n",
    "    X = model.encode(original_data, batch_size=batch_size, show_progress_bar=True, device='cpu')  # Ensure CPU usage\n",
    "    X_list.append(X)\n",
    "    np.savetxt(f'data/drifted_data/mix/original_{levels[i]}.csv', X, delimiter=',')\n",
    "\n",
    "    print(f\"start vectorizing mix drifted {levels[i]}\")\n",
    "    # Encode drifted data in batches\n",
    "    drifted_data = mix_full_dfs[i].drifted_preprocessed_data\n",
    "    X_drifted = model.encode(drifted_data, batch_size=batch_size, show_progress_bar=True, device='cpu')  # Ensure CPU usage\n",
    "    X_drifted_list.append(X_drifted)\n",
    "    np.savetxt(f'data/drifted_data/mix/drifted_{levels[i]}.csv', X_drifted, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numoy arrays containing original and drifted data\n",
    "\n",
    "levels = [0.1, 0.5, 0.9]\n",
    "\n",
    "X_typo_list = []\n",
    "X_typo_drifted_list = []\n",
    "X_pho_list = []\n",
    "X_pho_drifted_list = []\n",
    "X_mix_list = []\n",
    "X_mix_drifted_list = []\n",
    "\n",
    "for level in levels:\n",
    "    X = np.genfromtxt(f'data/drifted_data/typographical/original_{level}.csv', delimiter=',')\n",
    "    X_typo_list.append(X)\n",
    "    X_typo_drifted = np.genfromtxt(f'data/drifted_data/typographical/drifted_{level}.csv', delimiter=',')\n",
    "    X_typo_drifted_list.append(X_drifted)\n",
    "\n",
    "    X = np.genfromtxt(f'data/drifted_data/phonetic/original_{level}.csv', delimiter=',')\n",
    "    X_pho_list.append(X)\n",
    "    X_pho_drifted = np.genfromtxt(f'data/drifted_data/phonetic/drifted_{level}.csv', delimiter=',')\n",
    "    X_pho_drifted_list.append(X_drifted)\n",
    "\n",
    "    X = np.genfromtxt(f'data/drifted_data/mix/original_{level}.csv', delimiter=',')\n",
    "    X_mix_list.append(X)\n",
    "    X_mix_drifted = np.genfromtxt(f'data/drifted_data/mix/drifted_{level}.csv', delimiter=',')\n",
    "    X_mix_drifted_list.append(X_drifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity at level 0.1: 0.8500\n",
      "Average Cosine Similarity at level 0.5: 0.8500\n",
      "Average Cosine Similarity at level 0.9: 0.8500\n",
      "Average Cosine Similarity at level 0.1: 0.8500\n",
      "Average Cosine Similarity at level 0.5: 0.8500\n",
      "Average Cosine Similarity at level 0.9: 0.8500\n",
      "Average Cosine Similarity at level 0.1: 0.8500\n",
      "Average Cosine Similarity at level 0.5: 0.8500\n",
      "Average Cosine Similarity at level 0.9: 0.8500\n"
     ]
    }
   ],
   "source": [
    "plot_cosine_similarity(\n",
    "    levels=levels,\n",
    "    error_type=WordErrorType.TYPOGRAPHICAL,\n",
    "    X_list=X_typo_list,\n",
    "    X_drifted_list=X_typo_drifted_list,\n",
    ")\n",
    "plot_cosine_similarity(\n",
    "    levels=levels,\n",
    "    error_type=WordErrorType.PHONETIC,\n",
    "    X_list=X_pho_list,\n",
    "    X_drifted_list=X_pho_drifted_list,\n",
    ")\n",
    "plot_cosine_similarity(\n",
    "    levels=levels,\n",
    "    error_type=WordErrorType.MIX,\n",
    "    X_list=X_mix_list,\n",
    "    X_drifted_list=X_mix_drifted_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
